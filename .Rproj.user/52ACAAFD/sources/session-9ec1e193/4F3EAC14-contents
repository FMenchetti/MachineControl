##################################################################################################

### LOSING CONTROL (GROUP)? THE MACHINE LEARNING CONTROL METHOD FOR COUNTERFACTUAL FORECASTING ###    

##################################################################################################    

##################################################################################################################################################
##################################################################################################################################################

##                                                            
##  AUTHORS: Augusto Cerqua (Sapienza University of Rome), Marco Letta (Sapienza University of Rome), Fiammetta Menchetti (University of Florence) ##
##                                                            
##  DATE: October 2023 ##
##

##################################################################################################################################################
##################################################################################################################################################

#===========================================================================================================================================================================#
#   This R script contains the full codes employed to produce the results reported in the empirical application of the paper using GINI INDEX CHANGE as the outcome variable
#===========================================================================================================================================================================#

# R version 4.3.1

rm(list=ls())
# 1) SET SEED FOR REPRODUCIBILITY; LOAD THE REQUIRED PACKAGES
set.seed(25092023)
library(boot)
library(boot.pval) 
library(caret)
library(CAST)
library(dplyr)
library(purrr)
library("microbenchmark")
library("matrixStats")
library(corrplot)

setwd("C:\\Users\\fiamm\\Documents\\MLCM\\Replication code - Education inequality")
#setwd("G:\\Drive condivisi\\MLCM\\Replication code - Education inequality")
# 2) LOAD THE FULL DATASET, GENERATE TWO DISTINCT DATASETS (PRE- AND POST-TREATMENT), AND ARRANGE DATA AS NECESSARY FOR THE ANALYSIS
dataset_full <- read.csv("dataset_2016-2020_change_SLL_fixed_Invalsi_mat_std.csv", na.strings=c("",".","NA"))
names(dataset_full)
dataset_pre_2020 <- subset(dataset_full, year<2020) # subset data from the pre-treatment period
dataset_2020 <- subset(dataset_full, year==2020) # subset data from the treatment period, leave it aside for the final estimation of treatment effects later on
# from now on work exclusively on pre-treatment sample
names(dataset_pre_2020)
dataset_pre_2020_cleaned <- dataset_pre_2020[,c(2:157)] # remove ID variable that will not be considered for the cleaning steps
names(dataset_pre_2020_cleaned)


## PRELIMINARY RANDOM FOREST ##
mtry <- (ncol(dataset_pre_2020_cleaned)/3)
tunegrid <- expand.grid(.mtry=mtry)
dataset_pre_2020_preliminary <- dataset_pre_2020_cleaned[,-2] # remove time variable that creates issues due to lack of variance
preliminary_rf <- train(punt_wle_medio_mat5 ~ .,
                        data = dataset_pre_2020_preliminary,
                        method = "rf",
                        metric = "RMSE",
                        trControl = trainControl(method="none"),
                        tuneGrid=tunegrid, 
                        ntree=1000)
rf_Imp <- varImp(preliminary_rf, scale = TRUE)
plot(rf_Imp, top = 15)
names(dataset_pre_2020_preliminary)
dataset_pre_2020_noy <- dataset_pre_2020_preliminary[,c(1,3:155)]
rf_Imp
View(rf_Imp[["importance"]])
punt_wle_medio_mat5 <- dataset_pre_2020_cleaned$punt_wle_medio_mat5
year <- dataset_pre_2020_cleaned$year

## Creation of several datasets containing the ? most predictive covariates
dataset_pre_2020_cleaned_8 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>20)
dataset_pre_2020_cleaned_8 <- cbind(punt_wle_medio_mat5, year, dataset_pre_2020_cleaned_8) 
dataset_pre_2020_cleaned_10 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>10)
dataset_pre_2020_cleaned_10 <- cbind(punt_wle_medio_mat5, year, dataset_pre_2020_cleaned_10) 
dataset_pre_2020_cleaned_12 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>7)
dataset_pre_2020_cleaned_12 <- cbind(punt_wle_medio_mat5, year, dataset_pre_2020_cleaned_12) 
dataset_pre_2020_cleaned_14 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>6.4)
dataset_pre_2020_cleaned_14 <- cbind(punt_wle_medio_mat5, year, dataset_pre_2020_cleaned_14) 
dataset_pre_2020_cleaned_19 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>6)
dataset_pre_2020_cleaned_19 <- cbind(punt_wle_medio_mat5, year, dataset_pre_2020_cleaned_19) 


options(scipen=999)
dataset_pre_2020_cleaned_8_cv <- dataset_pre_2020_cleaned_8
dataset_pre_2020_cleaned_10_cv <- dataset_pre_2020_cleaned_10
dataset_pre_2020_cleaned_12_cv <- dataset_pre_2020_cleaned_12
dataset_pre_2020_cleaned_14_cv <- dataset_pre_2020_cleaned_14
dataset_pre_2020_cleaned_19_cv <- dataset_pre_2020_cleaned_19

#----------------------- COMMENTI ---------------------------------------------------------
# 
# Mi sembra di capire che 'cod_sll2011' è l'ID; 'year' è la variabile temporale (ci sono 3 tempi pre-int
# dal 2017 al 2019 e un tempo post, il 2020); 'punt_wle_medio_mat5' è la Y. Dopo la RF iniziale, si decide di
# usare come predittori le prime 14 variabili in termini di variable importance.
# Quindi, se il replication package deve partire da qui, posso direttamente fare un dataset ridotto che oltre
# alla Y, la variabile ID e il tempo, contenga anche queste variabili. Il resto lo fa il pacchetto
#-------------------------------------------------------------------------------------------

######################################################
### 21/15/20/25 - the 14 most predictive variables ###
######################################################
set.seed(25092023)
dataset_pre_2020_cleaned_cv <- dataset_pre_2020_cleaned_14

# 3) TRAIN, CROSS-VALIDATE, AND TEST MODELS; COMPUTE PERFORMANCE METRICS ON TEST DATA
dataset_pre_2020_cleaned <- dataset_pre_2020_cleaned_cv
dataset_pre_2018 <- subset(dataset_pre_2020_cleaned, year < 2018)
dataset_2018 <- subset(dataset_pre_2020_cleaned, year==2018)
dataset_pre_2019 <- subset(dataset_pre_2020_cleaned, year < 2019)
dataset_2019 <- subset(dataset_pre_2020_cleaned, year==2019)


# 3A. PREPARATION FOR TEMPORAL CROSS-VALIDATION
# generate folds for panel cross-validation: first, the CAST package is used to generate separate testing sets for each year; next, those sets are manually combined to generate combinations of training and testing sets for different years
indices <- CreateSpacetimeFolds(dataset_pre_2020_cleaned_cv, timevar = "year",
                                k=length(unique(dataset_pre_2020_cleaned_cv$year)))
indices
indexOut <- indices$indexOut
train1 <- indexOut[c(1)] # 2017 training fold (for forecasting on 2018)
train1
train1 <- unlist(train1, recursive = FALSE)
train2 <- indexOut[c(1,2)] # 2017 & 2018 training fold (for forecasting on 2019)
train2
train2 <- unlist(train2, recursive = FALSE)
train2
train <- list(train1, train2)
train
test1 <- indexOut[c(2)] # 2018 testing fold
test1
test1 <- unlist(test1, recursive = FALSE)
test2 <- indexOut[c(3)] # 2019 testing fold
test2
test2 <- unlist(test2, recursive = FALSE)
test <- list(test1, test2) # group all testing folds together
test
str(train) # check training folds
str(test) # check testing folds
dataset_pre_2020_cleaned_cv <- dataset_pre_2020_cleaned_cv[,-2] # remove time variable that creates issues due to lack of variance
dataset_pre_2018 <- dataset_pre_2018[,-2]
dataset_2018 <- dataset_2018[,-2]
dataset_pre_2019 <- dataset_pre_2019[,-2]
dataset_2019 <- dataset_2019[,-2]




# 3B. TEMPORAL CROSS-VALIDATION
# set control function by specifying the training and testing folds that caret will use for cross-validation and tuning of the hyperparameters (i.e., the combination of folds defined above)
ctrl <- trainControl(index = train, indexOut = test)

# now let's tune the hyperparameters of each of the ML algorithms via temporal cross-validation
# Stochasting gradient boosting
gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3), 
                        n.trees=c(1000, 1500), 
                        shrinkage = c(0.002, 0.005, 0.01),
                        n.minobsinnode = c(10, 15, 20))
bo <- train(punt_wle_medio_mat5 ~ .,
            data = dataset_pre_2020_cleaned_cv,
            method = "gbm",
            metric = "RMSE",
            #preProc = c("range","spatialSign","pca"),
            trControl = ctrl,
            #trControl = trainControl(method = "boot"),
            tuneGrid = gbmGrid)
bo$bestTune

# Random forest
rfGrid <-  expand.grid(mtry = c(round(ncol(dataset_pre_2020_cleaned_cv)/2),round(ncol(dataset_pre_2020_cleaned_cv)/3),round(ncol(dataset_pre_2020_cleaned_cv)/6)))
rf <- train(punt_wle_medio_mat5 ~ .,
            data = dataset_pre_2020_cleaned_cv,
            method = "rf",
            metric = "RMSE",
            #preProc = c("range","spatialSign","pca"),
            trControl = ctrl,
            tuneGrid = rfGrid,
            ntree=1000)
rf$bestTune

# LASSO_no_inter
lasso_no_inter <- train(punt_wle_medio_mat5 ~ .,
                        data = dataset_pre_2020_cleaned_cv,
                        method = "lasso",
                        metric = "RMSE",
                        trControl = ctrl,
                        preProc=c("center", "scale"))
lasso_no_inter$bestTune

# PLS
pls <- train(punt_wle_medio_mat5 ~ .,
             data = dataset_pre_2020_cleaned_cv,
             method = "pls",
             metric = "RMSE",
             #preProc = c("range","spatialSign","pca"),
             tuneLength = 20,
             trControl = ctrl)
pls$bestTune



############################################################################
# 3C. FORECASTING ON  PRE-TREATMENT YEARS  
# re-running models with the fine-tuned hyperparameters on the full datasets
# generate subsets of the main dataset
############################################################################

# Stochastic gradient boosting
# 2018
bo2018 <- train(punt_wle_medio_mat5 ~ .,
                data = dataset_pre_2018,
                method = "gbm",
                #               distribution = "tdist",
                metric = "RMSE",
                #preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="boot"),
                tuneGrid = bo$bestTune)

pred.bo.2018 <- predict(bo2018, newdata=dataset_2018)
mse.bo.2018 <- mean((dataset_2018$punt_wle_medio_mat5-pred.bo.2018)^2)
mse.test.ind.bo.2018=((dataset_2018$punt_wle_medio_mat5-pred.bo.2018)^2)
# 2019
bo2019 <- train(punt_wle_medio_mat5 ~ .,
                data = dataset_pre_2019,
                method = "gbm",
                #               distribution = "tdist",
                metric = "RMSE",
                #preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="boot"),
                tuneGrid = bo$bestTune)

pred.bo.2019 <- predict(bo2019, newdata=dataset_2019)
tef <- dataset_2019$punt_wle_medio_mat5 - pred.bo.2019
atef <- mean(tef)
mse.bo.2019 <- mean((dataset_2019$punt_wle_medio_mat5-pred.bo.2019)^2)
mse.test.ind.bo.2019=((dataset_2019$punt_wle_medio_mat5-pred.bo.2019)^2)
mse.bo <- (mse.bo.2018+mse.bo.2019)/2 # average performance measure for boosting across all pre-treatment years
mse.bo


# Random forest
# 2018
rf2018 <- train(punt_wle_medio_mat5 ~ .,
                data = dataset_pre_2018,
                method = "rf",
                metric = "RMSE",
                #preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="none"),
                tuneGrid = rf$bestTune,
                ntree=1000)
pred.rf.2018 <- predict(rf2018, newdata=dataset_2018)
mse.rf.2018 <- mean((dataset_2018$punt_wle_medio_mat5-pred.rf.2018)^2)
mse.test.ind.rf.2018=((dataset_2018$punt_wle_medio_mat5-pred.rf.2018)^2)
# 2019
rf2019 <- train(punt_wle_medio_mat5 ~ .,
                data = dataset_pre_2019,
                method = "rf",
                metric = "RMSE",
                #preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="none"),
                tuneGrid = rf$bestTune,
                ntree=1000)
pred.rf.2019 <- predict(rf2019, newdata=dataset_2019)
mse.rf.2019 <- mean((dataset_2019$punt_wle_medio_mat5-pred.rf.2019)^2)
mse.test.ind.rf.2019=((dataset_2019$punt_wle_medio_mat5-pred.rf.2019)^2)
mse.rf <- (mse.rf.2018+mse.rf.2019)/2 # average performance measure for random forest across all pre-treatment years
mse.rf 


# LASSO_no_inter
# 2018
lasso_no_inter2018 <- train(punt_wle_medio_mat5 ~ .,
                            data = dataset_pre_2018,
                            method = "lasso",
                            metric = "RMSE",
                            trControl = trainControl(method="none"),
                            tuneGrid = lasso_no_inter$bestTune,
                            preProc=c("center", "scale"))
pred.lasso_no_inter.2018 <- predict(lasso_no_inter2018, newdata=dataset_2018)
mse.lasso_no_inter.2018 <- mean((dataset_2018$punt_wle_medio_mat5-pred.lasso_no_inter.2018)^2)
mse.test.ind.lasso_no_inter.2018=((dataset_2018$punt_wle_medio_mat5-pred.lasso_no_inter.2018)^2)
# 2019
lasso_no_inter2019 <- train(punt_wle_medio_mat5 ~ .,
                            data = dataset_pre_2019,
                            method = "lasso",
                            metric = "RMSE",
                            trControl = trainControl(method="none"),
                            tuneGrid = lasso_no_inter$bestTune,
                            preProc=c("center", "scale"))
pred.lasso_no_inter.2019 <- predict(lasso_no_inter2019, newdata=dataset_2019)
mse.lasso_no_inter.2019 <- mean((dataset_2019$punt_wle_medio_mat5-pred.lasso_no_inter.2019)^2)
mse.test.ind.lasso_no_inter.2019=((dataset_2019$punt_wle_medio_mat5-pred.lasso_no_inter.2019)^2)
mse.lasso_no_inter <- (mse.lasso_no_inter.2018+mse.lasso_no_inter.2019)/2 # average performance measure for lasso across all pre-treatment years
mse.lasso_no_inter


# PLS
# 2018
pls2018 <- train(punt_wle_medio_mat5 ~ .,
                 data = dataset_pre_2018,
                 method = "pls",
                 metric = "RMSE",
                 #preProc = c("range","spatialSign","pca"),
                 trControl = trainControl(method="none"),
                 tuneGrid = pls$bestTune)

pred.pls.2018 <- predict(pls2018, newdata=dataset_2018)
mse.pls.2018 <- mean((dataset_2018$punt_wle_medio_mat5-pred.pls.2018)^2)
mse.test.ind.pls.2018=((dataset_2018$punt_wle_medio_mat5-pred.pls.2018)^2)
# 2019
pls2019 <- train(punt_wle_medio_mat5 ~ .,
                 data = dataset_pre_2019,
                 method = "pls",
                 metric = "RMSE",
                 #preProc = c("range","spatialSign","pca"),
                 trControl = trainControl(method="none"),
                 tuneGrid = pls$bestTune)

pred.pls.2019 <- predict(pls2019, newdata=dataset_2019)
mse.pls.2019 <- mean((dataset_2019$punt_wle_medio_mat5-pred.pls.2019)^2)
mse.test.ind.pls.2019=((dataset_2019$punt_wle_medio_mat5-pred.pls.2019)^2)
mse.pls <- (mse.pls.2018+mse.pls.2019)/2 # average performance measure for boosting across all pre-treatment years
mse.pls




mse.bo.2018
mse.bo.2019
mse.rf.2018
mse.rf.2019
mse.lasso_no_inter.2018
mse.lasso_no_inter.2019
mse.pls.2018
mse.pls.2019


mse.lasso_no_inter
mse.pls
mse.bo
mse.rf

# export
cod_sll2011 <- dataset_2020$cod_sll2011
pre.treatment.export <- cbind(cod_sll2011, mse.bo, mse.pls, mse.rf, pred.bo.2018, pred.bo.2019, pred.pls.2018, pred.pls.2019, pred.rf.2018, pred.rf.2019)
write.csv(pre.treatment.export,"pre.treatment.results.change_2023_Invalsi_mat_std.csv", row.names = FALSE)





# 4 FORECASTING ON POST-TREATMENT DATA; ESTIMATION OF TREATMENT EFFECTS; BOOTSTRAPPING 
# i) forecast counterfactual outcomes; ii) estimate treatment effects; iii) compute bootstrap standard errors -- repeat first for individual estimates, then for ATE
# 4.A) Individual treatment effects with standard errors
set.seed(25092023)

bo2020 <- train(punt_wle_medio_mat5 ~ .,
                data = dataset_pre_2020_cleaned,
                method = "gbm",
                metric = "RMSE",
                trControl = trainControl(method="none"),
                tuneGrid = bo$bestTune)
pred.bo.2020 <- predict(bo2020, newdata=dataset_2020)
te.bo.2020=dataset_2020$punt_wle_medio_mat5-pred.bo.2020


rf2020 <- train(punt_wle_medio_mat5 ~ .,
                data = dataset_pre_2020_cleaned,
                method = "rf",
                metric = "RMSE",
                trControl = trainControl(method="none"),
                tuneGrid = rf$bestTune,
                ntree=1000)
pred.rf.2020 <- predict(rf2020, newdata=dataset_2020)
te.rf.2020=dataset_2020$punt_wle_medio_mat5-pred.rf.2020


lasso_no_inter2020 <- train(punt_wle_medio_mat5 ~ .,
                            data = dataset_pre_2020_cleaned,
                            method = "lasso",
                            metric = "RMSE",
                            trControl = trainControl(method="none"),
                            tuneGrid = lasso_no_inter$bestTune,
                            preProc=c("center", "scale"))
pred.lasso_no_inter.2020 <- predict(lasso_no_inter2020, newdata=dataset_2020)
te.lasso_no_inter.2020=dataset_2020$punt_wle_medio_mat5-pred.lasso_no_inter.2020


pls2020 <- train(punt_wle_medio_mat5 ~ .,
                 data = dataset_pre_2020_cleaned,
                 method = "pls",
                 metric = "RMSE",
                 trControl = trainControl(method="none"),
                 tuneGrid = pls$bestTune)
pred.pls.2020 <- predict(pls2020, newdata=dataset_2020)
te.pls.2020=dataset_2020$punt_wle_medio_mat5-pred.pls.2020


treatment.export <- cbind(cod_sll2011, te.bo.2020, te.pls.2020, te.lasso_no_inter.2020, te.rf.2020)
write.csv(treatment.export,"treatment.results.change_2023_Invalsi_mat_std.csv", row.names = FALSE)

nboot = 1000
dataset_pre_2020$cod_sll2011 <- as.character(dataset_pre_2020$cod_sll2011)
dataset_full$cod_sll2011 <- as.character(dataset_full$cod_sll2011)
dataset_pre_2020_cleaned <- cbind(dataset_pre_2020_cleaned, dataset_pre_2020$cod_sll2011)
### Step 1. Sampling indices
names(dataset_pre_2020_cleaned)
ind <- which(dataset_pre_2020_cleaned[, "year"] < 2020)
ids <- unique(dataset_full$cod_sll2011)
ii <- t(sapply(1:nboot, function(boot){set.seed(25092023); ind1 <- sample(ids, size = length(ids), replace = T); 
unlist(sapply(ind1, function(x)(intersect(which(dataset_pre_2020_cleaned[, "dataset_pre_2020$cod_sll2011"] %in% x), ind)), simplify = F))}))

ii2 <- t(sapply(1:nboot, function(boot){set.seed(25092023); ind1 <- sample(ids, size = length(ids), replace = T); 
unlist(sapply(ind1, function(x)(intersect(which(dataset_pre_2020_cleaned[, "dataset_pre_2020$cod_sll2011"] %in% x), ind)), simplify = F))}))

# BOOTSTRAPPING THE 2020 ATE
dataset_pre_2020_cleaned <- dataset_pre_2020_cleaned[, c(1:16)]
names(dataset_pre_2020_cleaned)
boot_ate <- apply(ii, 1, function(i){
  rf2020 <- train(punt_wle_medio_mat5 ~ .,
                  data = dataset_pre_2020_cleaned,
                  method = "rf",
                  metric = "RMSE",
                  trControl = trainControl(method="none"),
                  tuneGrid = rf$bestTune,
                  ntree=1000)
  pred.rf.2020 <- predict(rf2020, newdata=dataset_2020)
  te.rf.2020=dataset_2020$punt_wle_medio_mat5-pred.rf.2020
})
mean_ate_boot <- colMeans(boot_ate)
ate <- mean(mean_ate_boot)
se_ate <- sd(mean_ate_boot)
conf.ate <- quantile(mean_ate_boot, probs = c(0.025, 0.975))
ate.results <- cbind(ate, se_ate, conf.ate)
write.csv(ate.results,"ate_Invalsi_mat_std.csv", row.names = FALSE)

