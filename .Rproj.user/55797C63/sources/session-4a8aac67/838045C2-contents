##################################################################################################

### LOSING CONTROL (GROUP)? THE MACHINE LEARNING CONTROL METHOD FOR COUNTERFACTUAL FORECASTING ###    

##################################################################################################    

##################################################################################################################################################
##################################################################################################################################################

##                                                            
##  AUTHORS: Augusto Cerqua (Sapienza University of Rome), Marco Letta (Sapienza University of Rome), Fiammetta Menchetti (University of Florence) ##
##                                                            
##  DATE: July 2023 ##
##

##################################################################################################################################################
##################################################################################################################################################

#===========================================================================================================================================================================#
#   This R script contains the full codes employed to produce the results reported in the empirical application of the paper using GINI INDEX CHANGE as the outcome variable
#===========================================================================================================================================================================#

rm(list=ls())
# 1) SET SEED FOR REPRODUCIBILITY; LOAD THE REQUIRED PACKAGES
set.seed(21072023) # today's date
library(boot)
library(boot.pval) 
library(caret)
library(CAST)
library(dplyr)
library(purrr)
library("microbenchmark")
library("matrixStats")
library(corrplot)

# 2) LOAD THE FULL DATASET, GENERATE TWO DISTINCT DATASETS (PRE- AND POST-TREATMENT), AND ARRANGE DATA AS NECESSARY FOR THE ANALYSIS
dataset_full <- read.csv("G:\\.shortcut-targets-by-id\\1i5-qtC1rjP-qk_Qyip_3Cvz0sVoPwyLK\\Big data comunali\\Big data comunali - output files\\Income application\\data and codes\\gini\\GINI SLL\\dataset_2016-2020_change_SLL_fixed_log.csv", na.strings=c("",".","NA"))
names(dataset_full)
dataset_full <- dataset_full[,-5] # exclude Gini index levels
dataset_pre_2020 <- subset(dataset_full, year<2020) # subset data from the pre-treatment period
dataset_2020 <- subset(dataset_full, year==2020) # subset data from the treatment period, leave it aside for the final estimation of treatment effects later on
# from now on work exclusively on pre-treatment sample
names(dataset_pre_2020)
dataset_pre_2020_cleaned <- dataset_pre_2020[,c(2:129)] # remove ID variable that will not be considered for the cleaning steps
names(dataset_pre_2020_cleaned)
#corr <- as.data.frame((abs(cor(dataset_pre_2020_cleaned)[,3]) > 0.15)) # compute Pearson correlations between the outcome and all the predictors, flag predictors with a correlation higher than a specified threshold (here 0.15)
#corr
#dataset_pre_2020_cleaned <- dataset_pre_2020_cleaned %>% select_if(corr > 0.15) # keep only predictors with a correlation higher than the selected threshold
mtry <- (ncol(dataset_pre_2020_cleaned)/3)
tunegrid <- expand.grid(.mtry=mtry)
dataset_pre_2020_preliminary <- dataset_pre_2020_cleaned[,-2] # remove time variable that creates issues due to lack of variance
preliminary_rf <- train(log_gini_index_chg ~ .,
            data = dataset_pre_2020_preliminary,
            method = "rf",
            metric = "RMSE",
            trControl = trainControl(method="none"),
            tuneGrid=tunegrid, 
            ntree=1000)
rf_Imp <- varImp(preliminary_rf, scale = TRUE)
plot(rf_Imp, top = 15)
dataset_pre_2020_noy <- dataset_pre_2020_preliminary[,c(1,3:127)]
rf_Imp
View(rf_Imp[["importance"]])
log_gini_index_chg <- dataset_pre_2020_cleaned$log_gini_index_chg
year <- dataset_pre_2020_cleaned$year
dataset_pre_2020_cleaned_9 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>29.5)
dataset_pre_2020_cleaned_9 <- cbind(log_gini_index_chg, year, dataset_pre_2020_cleaned_9) 
dataset_pre_2020_cleaned_11 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>28)
dataset_pre_2020_cleaned_11 <- cbind(log_gini_index_chg, year, dataset_pre_2020_cleaned_11) 
dataset_pre_2020_cleaned_13 <- dataset_pre_2020_noy %>% select_if(rf_Imp$importance>26.7)
dataset_pre_2020_cleaned_13 <- cbind(log_gini_index_chg, year, dataset_pre_2020_cleaned_13) 

options(scipen=999)
dataset_pre_2020_cleaned_9_cv <- dataset_pre_2020_cleaned_9
dataset_pre_2020_cleaned_11_cv <- dataset_pre_2020_cleaned_11
dataset_pre_2020_cleaned_13_cv <- dataset_pre_2020_cleaned_13


#############################################
### 21/15/20/25 most predictive variables ###
#############################################
set.seed(21072023)
dataset_pre_2020_cleaned_cv <- dataset_pre_2020_cleaned_11

# 3) TRAIN, CROSS-VALIDATE, AND TEST MODELS; COMPUTE PERFORMANCE METRICS ON TEST DATA
dataset_pre_2020_cleaned <- dataset_pre_2020_cleaned_cv
dataset_pre_2017 <- subset(dataset_pre_2020_cleaned, year < 2017)
dataset_2017 <- subset(dataset_pre_2020_cleaned, year==2017)
dataset_pre_2018 <- subset(dataset_pre_2020_cleaned, year < 2018)
dataset_2018 <- subset(dataset_pre_2020_cleaned, year==2018)
dataset_pre_2019 <- subset(dataset_pre_2020_cleaned, year < 2019)
dataset_2019 <- subset(dataset_pre_2020_cleaned, year==2019)


# 3A. PREPARATION FOR TEMPORAL CROSS-VALIDATION
# generate folds for panel cross-validation: first, the CAST package is used to generate separate testing sets for each year; next, those sets are manually combined to generate combinations of training and testing sets for different years
indices <- CreateSpacetimeFolds(dataset_pre_2020_cleaned_cv, timevar = "year",
                                k=length(unique(dataset_pre_2020_cleaned_cv$year)))
indices
indexOut <- indices$indexOut
train1 <- indexOut[c(1)] # 2016 training fold (for forecasting on 2017)
train1
train1 <- unlist(train1, recursive = FALSE)
train2 <- indexOut[c(1,2)] # 2016 & 2017 training fold (for forecasting on 2018)
train2
train2 <- unlist(train2, recursive = FALSE)
train2
train3 <- indexOut[c(1,2,3)] # 2016, 2017 & 2018 training fold (for forecasting on 2019)
train3
train3 <- unlist(train3, recursive = FALSE) # group all training folds together
train3
train <- list(train1, train2, train3)
train
test1 <- indexOut[c(2)] # 2017 testing fold
test1
test1 <- unlist(test1, recursive = FALSE)
test2 <- indexOut[c(3)] # 2018 testing fold
test2
test2 <- unlist(test2, recursive = FALSE)
test3 <- indexOut[c(4)] # 2019 testing fold
test3
test3 <- unlist(test3, recursive = FALSE)
test <- list(test1, test2, test3) # group all testing folds together
test
str(train) # check training folds
str(test) # check testing folds
dataset_pre_2020_cleaned_cv <- dataset_pre_2020_cleaned_cv[,-2] # remove time variable that creates issues due to lack of variance
dataset_pre_2017 <- dataset_pre_2017[,-2]
dataset_2017 <- dataset_2017[,-2]
dataset_pre_2018 <- dataset_pre_2018[,-2]
dataset_2018 <- dataset_2018[,-2]
dataset_pre_2019 <- dataset_pre_2019[,-2]
dataset_2019 <- dataset_2019[,-2]




# 3B. TEMPORAL CROSS-VALIDATION
# set control function by specifying the training and testing folds that caret will use for cross-validation and tuning of the hyperparameters (i.e., the combination of folds defined above)
ctrl <- trainControl(index = train, indexOut = test)

# now let's tune the hyperparameters of each of the ML algorithms via temporal cross-validation
# Stochasting gradient boosting
gbmGrid <-  expand.grid(interaction.depth = c(1, 2), 
                        n.trees=c(1000, 1500), 
                        shrinkage = c(0.008, 0.01, 0.012),
                        n.minobsinnode = c(4, 8, 12))
bo <- train(log_gini_index_chg ~ .,
            data = dataset_pre_2020_cleaned_cv,
            method = "gbm",
            metric = "RMSE",
#            preProc = c("range","spatialSign","pca"),
            trControl = ctrl,
#           trControl = trainControl(method = "boot"),
            tuneGrid = gbmGrid)
bo$bestTune

# Random forest
rf <- train(log_gini_index_chg ~ .,
            data = dataset_pre_2020_cleaned_cv,
            method = "rf",
            metric = "RMSE",
            #            preProc = c("range","spatialSign","pca"),
            trControl = ctrl,
            ntree=1000)
rf$bestTune

# LASSO
lasso <- train(log_gini_index_chg ~ .*.,
               data = dataset_pre_2020_cleaned_cv,
               method = "lasso",
               metric = "RMSE",
               trControl = ctrl,
               preProc=c("center", "scale"))

# LASSO_no_inter
lasso_no_inter <- train(log_gini_index_chg ~ .,
               data = dataset_pre_2020_cleaned_cv,
               method = "lasso",
               metric = "RMSE",
               trControl = ctrl,
               preProc=c("center", "scale"))
lasso_no_inter$bestTune

# PLS
pls <- train(log_gini_index_chg ~ .,
             data = dataset_pre_2020_cleaned_cv,
             method = "pls",
             metric = "RMSE",
             #preProc = c("range","spatialSign","pca"),
             tuneLength = 20,
             trControl = ctrl)
pls$bestTune


# 3C. FORECASTING ON  PRE-TREATMENT YEARS  
# re-running models with the fine-tuned hyperparameters on the full datasets
# generate subsets of the main dataset
# 2017
# Stochastic gradient boosting
bo2017 <- train(log_gini_index_chg ~ .,
                data = dataset_pre_2017,
                method = "gbm",
#               distribution = "tdist",
                metric = "RMSE",
#            preProc = c("range","spatialSign","pca"),
trControl = trainControl(method="none"),
                tuneGrid = bo$bestTune)
pred.bo.2017 <- predict(bo2017, newdata=dataset_2017)
mse.bo.2017 <- mean((dataset_2017$log_gini_index_chg-pred.bo.2017)^2)
mse.test.ind.bo.2017=((dataset_2017$log_gini_index_chg-pred.bo.2017)^2)
# 2018
bo2018 <- train(log_gini_index_chg ~ .,
                data = dataset_pre_2018,
                method = "gbm",
#               distribution = "tdist",
                metric = "RMSE",
#            preProc = c("range","spatialSign","pca"),
trControl = trainControl(method="none"),
                tuneGrid = bo$bestTune)

pred.bo.2018 <- predict(bo2018, newdata=dataset_2018)
mse.bo.2018 <- mean((dataset_2018$log_gini_index_chg-pred.bo.2018)^2)
mse.test.ind.bo.2018=((dataset_2018$log_gini_index_chg-pred.bo.2018)^2)
# 2019
bo2019 <- train(log_gini_index_chg ~ .,
                data = dataset_pre_2019,
                method = "gbm",
#               distribution = "tdist",
                metric = "RMSE",
#            preProc = c("range","spatialSign","pca"),
trControl = trainControl(method="none"),
                tuneGrid = bo$bestTune)

pred.bo.2019 <- predict(bo2019, newdata=dataset_2019)
tef <- dataset_2019$log_gini_index_chg - pred.bo.2019
atef <- mean(tef)
mse.bo.2019 <- mean((dataset_2019$log_gini_index_chg-pred.bo.2019)^2)
mse.test.ind.bo.2019=((dataset_2019$log_gini_index_chg-pred.bo.2019)^2)
mse.bo <- (mse.bo.2017+mse.bo.2018+mse.bo.2019)/3 # average performance measure for boosting across all pre-treatment years
mse.bo

bo.2019_Imp <- varImp(bo2019, scale = TRUE)
plot(bo.2019_Imp, top = 15)


# Random forest
# 2017
rf2017 <- train(log_gini_index_chg ~ .,
                data = dataset_pre_2017,
                method = "rf",
                metric = "RMSE",
                #            preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="none"),
                tuneGrid = rf$bestTune,
                ntree=1000)
pred.rf.2017 <- predict(rf2017, newdata=dataset_2017)
mse.rf.2017 <- mean((dataset_2017$log_gini_index_chg-pred.rf.2017)^2)
mse.test.ind.rf.2017=((dataset_2017$log_gini_index_chg-pred.rf.2017)^2)
# 2018
rf2018 <- train(log_gini_index_chg ~ .,
                data = dataset_pre_2018,
                method = "rf",
                metric = "RMSE",
                #            preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="none"),
                tuneGrid = rf$bestTune,
                ntree=1000)
pred.rf.2018 <- predict(rf2018, newdata=dataset_2018)
mse.rf.2018 <- mean((dataset_2018$log_gini_index_chg-pred.rf.2018)^2)
mse.test.ind.rf.2018=((dataset_2018$log_gini_index_chg-pred.rf.2018)^2)
# 2019
rf2019 <- train(log_gini_index_chg ~ .,
                data = dataset_pre_2019,
                method = "rf",
                metric = "RMSE",
                #            preProc = c("range","spatialSign","pca"),
                trControl = trainControl(method="none"),
                tuneGrid = rf$bestTune,
                ntree=1000)
pred.rf.2019 <- predict(rf2019, newdata=dataset_2019)
mse.rf.2019 <- mean((dataset_2019$log_gini_index_chg-pred.rf.2019)^2)
mse.test.ind.rf.2019=((dataset_2019$log_gini_index_chg-pred.rf.2019)^2)
mse.rf <- (mse.rf.2017+mse.rf.2018+mse.rf.2019)/3 # average performance measure for random forest across all pre-treatment years


# LASSO
# 2017
lasso2017 <- train(log_gini_index_chg ~ .*.,
                   data = dataset_pre_2017,
                   method = "lasso",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = lasso$bestTune,
                   preProc=c("center", "scale"))
pred.lasso.2017 <- predict(lasso2017, newdata=dataset_2017)
mse.lasso.2017 <- mean((dataset_2017$log_gini_index_chg-pred.lasso.2017)^2)
mse.test.ind.lasso.2017=((dataset_2017$log_gini_index_chg-pred.lasso.2017)^2)
# 2018
lasso2018 <- train(log_gini_index_chg ~ .*.,
                   data = dataset_pre_2018,
                   method = "lasso",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = lasso$bestTune,
                   preProc=c("center", "scale"))
pred.lasso.2018 <- predict(lasso2018, newdata=dataset_2018)
mse.lasso.2018 <- mean((dataset_2018$log_gini_index_chg-pred.lasso.2018)^2)
mse.test.ind.lasso.2018=((dataset_2018$log_gini_index_chg-pred.lasso.2018)^2)
# 2019
lasso2019 <- train(log_gini_index_chg ~ .*.,
                   data = dataset_pre_2019,
                   method = "lasso",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = lasso$bestTune,
                   preProc=c("center", "scale"))
pred.lasso.2019 <- predict(lasso2019, newdata=dataset_2019)
mse.lasso.2019 <- mean((dataset_2019$log_gini_index_chg-pred.lasso.2019)^2)
mse.test.ind.lasso.2019=((dataset_2019$log_gini_index_chg-pred.lasso.2019)^2)
mse.lasso <- (mse.lasso.2017+mse.lasso.2018+mse.lasso.2019)/3 # average performance measure for lasso across all pre-treatment years
mse.lasso


# LASSO_no_inter
# 2017
lasso_no_inter2017 <- train(log_gini_index_chg ~ .,
                   data = dataset_pre_2017,
                   method = "lasso",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = lasso_no_inter$bestTune,
                   preProc=c("center", "scale"))
pred.lasso_no_inter.2017 <- predict(lasso_no_inter2017, newdata=dataset_2017)
mse.lasso_no_inter.2017 <- mean((dataset_2017$log_gini_index_chg-pred.lasso_no_inter.2017)^2)
mse.test.ind.lasso_no_inter.2017=((dataset_2017$log_gini_index_chg-pred.lasso_no_inter.2017)^2)
# 2018
lasso_no_inter2018 <- train(log_gini_index_chg ~ .,
                   data = dataset_pre_2018,
                   method = "lasso",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = lasso_no_inter$bestTune,
                   preProc=c("center", "scale"))
pred.lasso_no_inter.2018 <- predict(lasso_no_inter2018, newdata=dataset_2018)
mse.lasso_no_inter.2018 <- mean((dataset_2018$log_gini_index_chg-pred.lasso_no_inter.2018)^2)
mse.test.ind.lasso_no_inter.2018=((dataset_2018$log_gini_index_chg-pred.lasso_no_inter.2018)^2)
# 2019
lasso_no_inter2019 <- train(log_gini_index_chg ~ .,
                   data = dataset_pre_2019,
                   method = "lasso",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = lasso_no_inter$bestTune,
                   preProc=c("center", "scale"))
pred.lasso_no_inter.2019 <- predict(lasso_no_inter2019, newdata=dataset_2019)
mse.lasso_no_inter.2019 <- mean((dataset_2019$log_gini_index_chg-pred.lasso_no_inter.2019)^2)
mse.test.ind.lasso_no_inter.2019=((dataset_2019$log_gini_index_chg-pred.lasso_no_inter.2019)^2)
mse.lasso_no_inter <- (mse.lasso_no_inter.2017+mse.lasso_no_inter.2018+mse.lasso_no_inter.2019)/3 # average performance measure for lasso across all pre-treatment years
mse.lasso_no_inter


# PLS
pls2017 <- train(log_gini_index_chg ~ .,
                 data = dataset_pre_2017,
                 method = "pls",
                 metric = "RMSE",
                 #preProc = c("range","spatialSign","pca"),
                 trControl = trainControl(method="none"),
                 tuneGrid = pls$bestTune)
pred.pls.2017 <- predict(pls2017, newdata=dataset_2017)
mse.pls.2017 <- mean((dataset_2017$log_gini_index_chg-pred.pls.2017)^2)
mse.test.ind.pls.2017=((dataset_2017$log_gini_index_chg-pred.pls.2017)^2)
# 2018
pls2018 <- train(log_gini_index_chg ~ .,
                 data = dataset_pre_2018,
                 method = "pls",
                 metric = "RMSE",
                 #preProc = c("range","spatialSign","pca"),
                 trControl = trainControl(method="none"),
                 tuneGrid = pls$bestTune)

pred.pls.2018 <- predict(pls2018, newdata=dataset_2018)
mse.pls.2018 <- mean((dataset_2018$log_gini_index_chg-pred.pls.2018)^2)
mse.test.ind.pls.2018=((dataset_2018$log_gini_index_chg-pred.pls.2018)^2)
# 2019
pls2019 <- train(log_gini_index_chg ~ .,
                 data = dataset_pre_2019,
                 method = "pls",
                 metric = "RMSE",
                 #preProc = c("range","spatialSign","pca"),
                 trControl = trainControl(method="none"),
                 tuneGrid = pls$bestTune)

pred.pls.2019 <- predict(pls2019, newdata=dataset_2019)
mse.pls.2019 <- mean((dataset_2019$log_gini_index_chg-pred.pls.2019)^2)
mse.test.ind.pls.2019=((dataset_2019$log_gini_index_chg-pred.pls.2019)^2)
mse.pls <- (mse.pls.2017+mse.pls.2018+mse.pls.2019)/3 # average performance measure for boosting across all pre-treatment years
mse.bo
mse.pls


mse.lasso
mse.lasso_no_inter
mse.pls
mse.bo
mse.rf


mse.bo.2017
mse.bo.2018
mse.bo.2019
mse.rf.2017
mse.rf.2018
mse.rf.2019
mse.lasso.2017
mse.lasso.2018
mse.lasso.2019
mse.lasso_no_inter.2017
mse.lasso_no_inter.2018
mse.lasso_no_inter.2019
mse.pls.2017
mse.pls.2018
mse.pls.2019

# export
setwd("G:\\.shortcut-targets-by-id\\1i5-qtC1rjP-qk_Qyip_3Cvz0sVoPwyLK\\Big data comunali\\Big data comunali - output files\\Income application\\data and codes\\gini\\GINI SLL\\Codes and results 2023")
cod_sll2011 <- dataset_2020$cod_sll2011
pre.treatment.export <- cbind(cod_sll2011, mse.bo, pred.bo.2017, pred.bo.2018, pred.bo.2019, pred.rf.2017, pred.rf.2018, pred.rf.2019)
write.csv(pre.treatment.export,"pre.treatment.results.change_2023_FINAL.csv", row.names = FALSE)






#### MAE ####
mae.pls.2019 <- mean(abs(dataset_2019$log_gini_index_chg-pred.pls.2019))
mae.pls.2018 <- mean(abs(dataset_2018$log_gini_index_chg-pred.pls.2018))
mae.pls.2017 <- mean(abs(dataset_2017$log_gini_index_chg-pred.pls.2017))
mae.pls <- (mae.pls.2017+mae.pls.2018+mae.pls.2019)/3
mae.lasso_no_inter.2019 <- mean(abs(dataset_2019$log_gini_index_chg-pred.lasso_no_inter.2019))
mae.lasso_no_inter.2018 <- mean(abs(dataset_2018$log_gini_index_chg-pred.lasso_no_inter.2018))
mae.lasso_no_inter.2017 <- mean(abs(dataset_2017$log_gini_index_chg-pred.lasso_no_inter.2017))
mae.lasso_no_inter <- (mae.lasso_no_inter.2017+mae.lasso_no_inter.2018+mae.lasso_no_inter.2019)/3
mae.bo.2019 <- mean(abs(dataset_2019$log_gini_index_chg-pred.bo.2019))
mae.bo.2018 <- mean(abs(dataset_2018$log_gini_index_chg-pred.bo.2018))
mae.bo.2017 <- mean(abs(dataset_2017$log_gini_index_chg-pred.bo.2017))
mae.bo <- (mae.bo.2017+mae.bo.2018+mae.bo.2019)/3
mae.rf.2019 <- mean(abs(dataset_2019$log_gini_index_chg-pred.rf.2019))
mae.rf.2018 <- mean(abs(dataset_2018$log_gini_index_chg-pred.rf.2018))
mae.rf.2017 <- mean(abs(dataset_2017$log_gini_index_chg-pred.rf.2017))
mae.rf <- (mae.rf.2017+mae.rf.2018+mae.rf.2019)/3


mae.lasso_no_inter
mae.pls
mae.bo
mae.rf
























# 4 FORECASTING ON POST-TREATMENT DATA; ESTIMATION OF TREATMENT EFFECTS; BOOTSTRAPPING 
# i) forecast counterfactual outcomes; ii) estimate treatment effects; iii) compute bootstrap standard errors -- repeat first for individual estimates, then for ATE
# 4.A) Individual treatment effects with standard errors
set.seed(21072023) # today's date

bo2020 <- train(log_gini_index_chg ~ .,
                   data = dataset_pre_2020_cleaned,
                   method = "gbm",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = bo$bestTune)
  pred.bo.2020 <- predict(bo2020, newdata=dataset_2020)
  te.bo.2020=dataset_2020$log_gini_index_chg-pred.bo.2020

  
rf2020 <- train(log_gini_index_chg ~ .,
                  data = dataset_pre_2020_cleaned,
                  method = "rf",
                  metric = "RMSE",
                  trControl = trainControl(method="none"),
                  tuneGrid = rf$bestTune,
                  ntree=1000)
pred.rf.2020 <- predict(rf2020, newdata=dataset_2020)
te.rf.2020=dataset_2020$log_gini_index_chg-pred.rf.2020

  
lasso_no_inter2020 <- train(log_gini_index_chg ~ .,
                              data = dataset_pre_2020_cleaned,
                              method = "lasso",
                              metric = "RMSE",
                              trControl = trainControl(method="none"),
                              tuneGrid = lasso_no_inter$bestTune,
                              preProc=c("center", "scale"))
pred.lasso_no_inter.2020 <- predict(lasso_no_inter2020, newdata=dataset_2020)
te.lasso_no_inter.2020=dataset_2020$log_gini_index_chg-pred.lasso_no_inter.2020


pls2020 <- train(log_gini_index_chg ~ .,
                   data = dataset_pre_2020_cleaned,
                   method = "pls",
                   metric = "RMSE",
                   trControl = trainControl(method="none"),
                   tuneGrid = pls$bestTune)
pred.pls.2020 <- predict(pls2020, newdata=dataset_2020)
te.pls.2020=dataset_2020$log_gini_index_chg-pred.pls.2020


treatment.export <- cbind(cod_sll2011, te.bo.2020, te.pls.2020, te.lasso_no_inter.2020, te.rf.2020)
write.csv(treatment.export,"treatment.results.change_2023_FINAL.csv", row.names = FALSE)
set.seed(21072023)
type <- "block"
nboot = 1000
dataset_pre_2020_cleaned <- cbind(dataset_pre_2020_cleaned, dataset_pre_2020$cod_sll2011)
### Step 1. Sampling indices
dataset_pre_2020_cleaned <- cbind(dataset_pre_2020_cleaned, dataset_pre_2020$cod_sll2011)
names(dataset_pre_2020_cleaned)
ids <- unique(dataset_pre_2020$cod_sll2011)
ii <- t(sapply(1:nboot, function(boot){set.seed(21072023); ind1 <- sample(ids, size = length(ids), replace = T)}))


# BOOTSTRAPPINT THE 2020 ATE
dataset_pre_2020_cleaned <- dataset_pre_2020_cleaned[, c(1:13)]
names(dataset_pre_2020_cleaned)
boot_ate <- apply(ii, 1, function(i){
  bo2020 <- train(log_gini_index_chg ~ .,
                  data = dataset_pre_2020_cleaned,
                  method = "gbm",
                  metric = "RMSE",
                  trControl = trainControl(method="none"),
                  tuneGrid = bo$bestTune)
  pred.bo.2020 <- predict(bo2020, newdata=dataset_2020)
  te.bo.2020=dataset_2020$log_gini_index_chg-pred.bo.2020
})
mean_ate_boot <- colMeans(boot_ate)
ate <- mean(mean_ate_boot)
se_ate <- sd(mean_ate_boot)
conf.ate <- quantile(mean_ate_boot, probs = c(0.025, 0.975))
ate.results <- cbind(ate, se_ate, conf.ate)
write.csv(ate.results,"ate.csv", row.names = FALSE)

# BOOTSTRAPPING THE PLACEBO ATE 17-19
  # export the results
  set.seed(21072023)
  boot_ate_2017_2019 <- apply(ii, 1, function(i){
    bo2017 <- train(log_gini_index_chg ~ .,
                    data = dataset_pre_2017,
                    method = "gbm",
                    #               distribution = "tdist",
                    metric = "RMSE",
                    #            preProc = c("range","spatialSign","pca"),
                    trControl = trainControl(method="none"),
                    tuneGrid = bo$bestTune)
    pred.bo.2017 <- predict(bo2017, newdata=dataset_2017)
    te.bo.2017=dataset_2017$log_gini_index_chg-pred.bo.2017
    bo2018 <- train(log_gini_index_chg ~ .,
                    data = dataset_pre_2018,
                    method = "gbm",
                    #               distribution = "tdist",
                    metric = "RMSE",
                    #            preProc = c("range","spatialSign","pca"),
                    trControl = trainControl(method="none"),
                    tuneGrid = bo$bestTune)
    pred.bo.2018 <- predict(bo2018, newdata=dataset_2018)
    te.bo.2018=dataset_2018$log_gini_index_chg-pred.bo.2018
    bo2019 <- train(log_gini_index_chg ~ .,
                    data = dataset_pre_2019,
                    method = "gbm",
                    #               distribution = "tdist",
                    metric = "RMSE",
                    #            preProc = c("range","spatialSign","pca"),
                    trControl = trainControl(method="none"),
                    tuneGrid = bo$bestTune)
    pred.bo.2019 <- predict(bo2019, newdata=dataset_2019)
    te.bo.2019=dataset_2019$log_gini_index_chg-pred.bo.2019
    te.bo = (te.bo.2017+te.bo.2018+te.bo.2019)/3
  })
  mean_ate_boot_2017_2019 <- colMeans(boot_ate_2017_2019)
  ate_placebo <- mean(mean_ate_boot_2017_2019)
  se_ate_placebo <- sd(mean_ate_boot_2017_2019)
  conf.ate_placebo <- quantile(mean_ate_boot_2017_2019, probs = c(0.025, 0.975))
  ate_placebo.results <- cbind(ate_placebo, se_ate_placebo, conf.ate_placebo)
  write.csv(ate_placebo.results,"ate_placebo.csv", row.names = FALSE)
  

  
