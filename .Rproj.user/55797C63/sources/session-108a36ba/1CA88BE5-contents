###############################################################################
##
## Panel Cross Validation
##
## Authors: Cerqua A., Letta M., Menchetti F.
##
## Date last modified: July 2023
##
###############################################################################

#' Panel Cross Validation
#'
#' @param data
#' @param post_period
#' @param blocked
#' @param metric
#' @param trControl
#' @param ML_methods
#'
#' @return
#' @export
#'
#' @examples
PanelCrossValidation <- function(data, post_period, blocked = 1, metric = "RMSE", trControl = NULL, ML_methods = NULL){

  ### Parameter checks
  if(!any(class(data) %in% "PanelMLCM")) stop("Invalid class in the PanelCrossValidation function, something is wrong with as.PanelMLCM")
  if(!(post_period %in% data[, "Time"])) stop("post_period must be contained in timevar")
  if(length(unique(data[, "Time"])) - 2 - blocked < 1) stop("Panel cross validation must be performed in at least one time period")
  if(blocked <= 0) stop("The number of 'blocked' time periods for panel cross validation must be at least 1")
  if(!metric %in% c("RMSE", "Rsquared")) stop("Metric not allowed, check documentation")
  if(is.list(ML_methods)){if(any(sapply(ML_methods, FUN = length) != 2)) stop("'ML_methods' must be a list of methods, each of length 2")}
  if(is.list(ML_methods)){
    if(any(sapply(ML_methods, FUN = function(x)(any(!names(x) %in% c("method", "tuneGrid")))))) stop("Each method in 'ML_methods' must be a named list, check documentation")}

  ### STEP 1. The CAST package is used to generate separate testing sets for each year
  Tt <- length(unique(data[, "Time"]))
  post_period <- post_period
  indices <- CreateSpacetimeFolds(data, timevar = "Time", k = Tt)
  trainx <- lapply(blocked:(Tt-2), FUN = function(x) unlist(indices$indexOut[1:x]))
  testx <- lapply(blocked:(Tt-2), FUN = function(x) unlist(indices$indexOut[[x+1]]))

  ### STEP 2. Set control function by specifying the training and testing folds that caret will use
  ###         for cross-validation and tuning of the hyperparameters (i.e., the combination of folds defined above)
  if(is.null(trControl)){

    ctrl <- trainControl(index = trainx, indexOut = testx)

  } else {

    ctrl <- trControl # da capire come fare i param checks

  }


  ### STEP 3.  Tune the hyperparameters of each of the ML algorithms via temporal cross-validation

  if(is.null(ML_methods)){

    # STOCHASTIC GRADIENT BOOSTING
    gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3),
                            n.trees=c(500, 1000, 1500, 2000),
                            shrinkage = seq(0.01, 0.1, by = 0.01),
                            n.minobsinnode = c(10,20))

    set.seed(1)
    bo <- train(Y ~ .,
                data = data[, !(names(data) %in% c("ID", "Time"))],
                method = "gbm",
                metric = metric,
                trControl = ctrl,
                tuneGrid = gbmGrid,
                verbose = FALSE)

    # RANDOM FOREST
    set.seed(1)
    rf <- train(Y ~ .,
                data = data[, !(names(data) %in% c("ID", "Time"))],
                method = "rf",
                metric = metric,
                search = "grid",
                trControl = ctrl,
                tuneGrid = expand.grid(mtry = (2:(ncol(data)-3))),
                ntree=500)
    # LASSO
    lasso <- train(Y ~ .,
                   data = data[, !(names(data) %in% c("ID", "Time"))],
                   method = "lasso",
                   metric = metric,
                   trControl = ctrl,
                   tuneGrid = expand.grid(fraction = seq(0.1, 0.9, by = 0.1)),
                   preProc=c("center", "scale"))

    # PLS
    pls <- train(Y ~ .,
                 data = data[, !(names(data) %in% c("ID", "Time"))],
                 method = "pls",
                 metric = metric,
                 trControl = ctrl,
                 tuneGrid = expand.grid(ncomp = c(1:10)),
                 preProc=c("center", "scale"))

    # Storing results in a list
    m_list <- list(bo = bo, rf = rf, lasso = lasso, pls = pls)

  } else {

   m_list <- lapply(ML_methods, FUN = function(x){train(Y ~.,
                                                  data = data[, !(names(data) %in% c("ID", "Time"))],
                                                  method = x$method,
                                                  metric = metric,
                                                  trControl = ctrl,
                                                  tuneGrid = x$tuneGrid)})

  }


  ### STEP 4. Selecting the "best" ML algorithm based on the provided performance metric
  rmse_min <- sapply(m_list, FUN = function(x) min(x$results[, metric]), simplify = T)
  ind <- which(rmse_min == min(rmse_min))

  ### Returning result
  return(best = m_list[[ind]])

}
