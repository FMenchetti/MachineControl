method = "pls",
metric = metric,
trControl = ctrl,
tuneGrid = expand.grid(ncomp = c(1:10)),
preProc=c("center", "scale"))
} else {
lapply(ML_methods, FUN = function(x)(train(Y ~.,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = x$method,
metric = metric,
trControl = ctrl,
tuneGrid = x$tuneGrid)))
}
### STEP 4. Selecting the "best" ML algorithm based on the provided performance metric
m_list <- list(bo = bo, rf = rf, lasso = lasso, pls = pls)
rmse_min <- sapply(m_list, FUN = function(x) min(x$results[, metric]), simplify = T)
ind <- which(rmse_min == min(rmse_min))
### Returning result
return(best = m_list[[ind]])
}
enet <- list(method = "enet",
tuneGrid = expand.grid(
fraction = seq(0.1, 0.9, by = 0.1),
lambda = seq(0.1, 0.9, by = 0.1)))
linreg <- list(method = "lm",
tuneGrid = expand.grid(
intercept = seq(0, 10, by = 0.5)))
pcv <- PanelCrossValidation(data = newdata, post_period = 2020, metric = "RMSE", ML_methods = list(enet, linreg))
ML_methods <- list(enet, linreg)
sapply(ML_methods, FUN = length)
sapply(ML_methods, FUN = length) != 2
all(sapply(ML_methods, FUN = length) != 2)
sapply(ML_methods, FUN = function(x)(names(x)))
sapply(ML_methods, FUN = function(x)(names(x) %in% c("method", "tuneGrid")))
sapply(ML_methods, FUN = function(x)(!names(x) %in% c("method", "tuneGrid")))
sapply(ML_methods, FUN = function(x)(any(!names(x) %in% c("method", "tuneGrid"))))
sapply(ML_methods, FUN = function(x)(any(any(!names(x) %in% c("method", "tuneGrid")))))
any(sapply(ML_methods, FUN = function(x)(any(!names(x) %in% c("method", "tuneGrid")))))
PanelCrossValidation <- function(data, post_period, blocked = 1, metric = "RMSE", trControl = NULL, ML_methods = NULL){
browser()
### Parameter checks
if(!any(class(data) %in% "PanelMLCM")) stop("Invalid class in the PanelCrossValidation function, something is wrong with as.PanelMLCM")
if(!(post_period %in% data[, "Time"])) stop("post_period must be contained in timevar")
if(length(unique(data[, "Time"])) - 2 - blocked < 1) stop("Panel cross validation must be performed in at least one time period")
if(blocked <= 0) stop("The number of 'blocked' time periods for panel cross validation must be at least 1")
if(!metric %in% c("RMSE", "Rsquared")) stop("Metric not allowed, check documentation")
if(is.list(ML_methods)){if(any(sapply(ML_methods, FUN = length) != 2)) stop("'ML_methods' must be a list of methods, each of length 2")}
if(is.list(ML_methods)){
if(any(sapply(ML_methods, FUN = function(x)(any(!names(x) %in% c("method", "tuneGrid")))))) stop("Each method in 'ML_methods' must be a named list, check documentation")}
### STEP 1. The CAST package is used to generate separate testing sets for each year
Tt <- length(unique(data[, "Time"]))
post_period <- post_period
indices <- CreateSpacetimeFolds(data, timevar = "Time", k = Tt)
trainx <- lapply(blocked:(Tt-2), FUN = function(x) unlist(indices$indexOut[1:x]))
testx <- lapply(blocked:(Tt-2), FUN = function(x) unlist(indices$indexOut[[x+1]]))
### STEP 2. Set control function by specifying the training and testing folds that caret will use
###         for cross-validation and tuning of the hyperparameters (i.e., the combination of folds defined above)
if(is.null(trControl)){
ctrl <- trainControl(index = trainx, indexOut = testx)
} else {
ctrl <- trControl # da capire come fare i param checks
}
### STEP 3.  Tune the hyperparameters of each of the ML algorithms via temporal cross-validation
if(is.null(ML_methods)){
# Stochastic gradient boosting
gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3),
n.trees=c(500, 1000, 1500, 2000),
shrinkage = seq(0.01, 0.1, by = 0.01),
n.minobsinnode = c(10,20))
set.seed(1)
bo <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "gbm",
metric = metric,
trControl = ctrl,
tuneGrid = gbmGrid,
verbose = FALSE)
# Random forest
set.seed(1)
rf <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "rf",
metric = metric,
search = "grid",
trControl = ctrl,
tuneGrid = expand.grid(mtry = (2:(ncol(data)-3))),
ntree=500)
# LASSO
lasso <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "lasso",
metric = metric,
trControl = ctrl,
tuneGrid = expand.grid(fraction = seq(0.1, 0.9, by = 0.1)),
preProc=c("center", "scale"))
# PLS
pls <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "pls",
metric = metric,
trControl = ctrl,
tuneGrid = expand.grid(ncomp = c(1:10)),
preProc=c("center", "scale"))
} else {
lapply(ML_methods, FUN = function(x)(train(Y ~.,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = x$method,
metric = metric,
trControl = ctrl,
tuneGrid = x$tuneGrid)))
}
### STEP 4. Selecting the "best" ML algorithm based on the provided performance metric
m_list <- list(bo = bo, rf = rf, lasso = lasso, pls = pls)
rmse_min <- sapply(m_list, FUN = function(x) min(x$results[, metric]), simplify = T)
ind <- which(rmse_min == min(rmse_min))
### Returning result
return(best = m_list[[ind]])
}
enet <- list(method = "enet",
tuneGrid = expand.grid(
fraction = seq(0.1, 0.9, by = 0.1),
lambda = seq(0.1, 0.9, by = 0.1)))
linreg <- list(method = "lm",
tuneGrid = expand.grid(
intercept = seq(0, 10, by = 0.5)))
pcv <- PanelCrossValidation(data = newdata, post_period = 2020, metric = "RMSE", ML_methods = list(enet, linreg))
source("~/GitHub/MLCM/R/panelcv.R")
PanelCrossValidation <- function(data, post_period, blocked = 1, metric = "RMSE", trControl = NULL, ML_methods = NULL){
browser()
### Parameter checks
if(!any(class(data) %in% "PanelMLCM")) stop("Invalid class in the PanelCrossValidation function, something is wrong with as.PanelMLCM")
if(!(post_period %in% data[, "Time"])) stop("post_period must be contained in timevar")
if(length(unique(data[, "Time"])) - 2 - blocked < 1) stop("Panel cross validation must be performed in at least one time period")
if(blocked <= 0) stop("The number of 'blocked' time periods for panel cross validation must be at least 1")
if(!metric %in% c("RMSE", "Rsquared")) stop("Metric not allowed, check documentation")
if(is.list(ML_methods)){if(any(sapply(ML_methods, FUN = length) != 2)) stop("'ML_methods' must be a list of methods, each of length 2")}
if(is.list(ML_methods)){
if(any(sapply(ML_methods, FUN = function(x)(any(!names(x) %in% c("method", "tuneGrid")))))) stop("Each method in 'ML_methods' must be a named list, check documentation")}
### STEP 1. The CAST package is used to generate separate testing sets for each year
Tt <- length(unique(data[, "Time"]))
post_period <- post_period
indices <- CreateSpacetimeFolds(data, timevar = "Time", k = Tt)
trainx <- lapply(blocked:(Tt-2), FUN = function(x) unlist(indices$indexOut[1:x]))
testx <- lapply(blocked:(Tt-2), FUN = function(x) unlist(indices$indexOut[[x+1]]))
### STEP 2. Set control function by specifying the training and testing folds that caret will use
###         for cross-validation and tuning of the hyperparameters (i.e., the combination of folds defined above)
if(is.null(trControl)){
ctrl <- trainControl(index = trainx, indexOut = testx)
} else {
ctrl <- trControl # da capire come fare i param checks
}
### STEP 3.  Tune the hyperparameters of each of the ML algorithms via temporal cross-validation
if(is.null(ML_methods)){
# STOCHASTIC GRADIENT BOOSTING
gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3),
n.trees=c(500, 1000, 1500, 2000),
shrinkage = seq(0.01, 0.1, by = 0.01),
n.minobsinnode = c(10,20))
set.seed(1)
bo <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "gbm",
metric = metric,
trControl = ctrl,
tuneGrid = gbmGrid,
verbose = FALSE)
# RANDOM FOREST
set.seed(1)
rf <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "rf",
metric = metric,
search = "grid",
trControl = ctrl,
tuneGrid = expand.grid(mtry = (2:(ncol(data)-3))),
ntree=500)
# LASSO
lasso <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "lasso",
metric = metric,
trControl = ctrl,
tuneGrid = expand.grid(fraction = seq(0.1, 0.9, by = 0.1)),
preProc=c("center", "scale"))
# PLS
pls <- train(Y ~ .,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = "pls",
metric = metric,
trControl = ctrl,
tuneGrid = expand.grid(ncomp = c(1:10)),
preProc=c("center", "scale"))
# Storing results in a list
m_list <- list(bo = bo, rf = rf, lasso = lasso, pls = pls)
} else {
m_list <- lapply(ML_methods, FUN = function(x){train(Y ~.,
data = data[, !(names(data) %in% c("ID", "Time"))],
method = x$method,
metric = metric,
trControl = ctrl,
tuneGrid = x$tuneGrid)})
}
### STEP 4. Selecting the "best" ML algorithm based on the provided performance metric
rmse_min <- sapply(m_list, FUN = function(x) min(x$results[, metric]), simplify = T)
ind <- which(rmse_min == min(rmse_min))
### Returning result
return(best = m_list[[ind]])
}
enet <- list(method = "enet",
tuneGrid = expand.grid(
fraction = seq(0.1, 0.9, by = 0.1),
lambda = seq(0.1, 0.9, by = 0.1)))
linreg <- list(method = "lm",
tuneGrid = expand.grid(
intercept = seq(0, 10, by = 0.5)))
pcv <- PanelCrossValidation(data = newdata, post_period = 2020, metric = "RMSE", ML_methods = list(enet, linreg))
source("~/GitHub/MLCM/R/panelcv.R")
source("~/GitHub/MLCM/R/panelcv.R")
source("~/GitHub/MLCM/R/panelcv.R")
source("~/GitHub/MLCM/R/panelcv.R")
class(ctrl)
source("~/GitHub/MLCM/R/panelcv.R")
source("~/GitHub/MLCM/R/panelcv.R")
library(MLCM)
install.packages("Rtools")
library(MLCM)
class(pcv)
source("~/GitHub/MLCM/R/panelcv.R")
library(MLCM)
newdata <- as.PanelMLCM(y = data[, "Y"], timevar = data[, "year"], id = data[, "ID"],
x = data[, !(names(data) %in% c("Y", "ID", "year"))])
# Using the first two years for training and the last two years for testing
indices <- CreateSpacetimeFolds(newdata, timevar = "Time", k = 5)
trainx <- indices$indexOut[1:2]
testx <- indices$indexOut[3:4]
ctrl <- trainControl(index = trainx, indexOut = testx)
enet <- list(method = "enet",
tuneGrid = expand.grid(
fraction = seq(0.1, 0.9, by = 0.1),
lambda = seq(0.1, 0.9, by = 0.1)))
linreg <- list(method = "lm",
tuneGrid = expand.grid(
intercept = seq(0, 10, by = 0.5)))
pcv <- PanelCrossValidation(data = newdata, post_period = 2020, ML_methods = list(enet, linreg))
causal <- MLCM(data = data, post_period = 2020, PCV = pcv)
library(MLCM)
causal <- MLCM(data = data, post_period = 2020, PCV = pcv)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
!is.null(y)
class(y)
library(MLCM)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
library(MLCM)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
!(is.null(y) | class(y) == "character")
library(MLCM)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
y %in% colnames(data)
library(MLCM)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
library(MLCM)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
post_period %in% data[, timevar]
post_period %in% data[, "Time"]
post_period %in% data[, timevar] | post_period %in% data[, "Time"]
2020 %in% data[, timevar] | 2020 %in% data[, "Time"]
library(MLCM)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv)
causal <- MLCM(data = newdata, post_period = 2020, PCV = pcv, inf_type = "block")
causal$ate
causal$ate.lower
causal$ate.upper
library(MLCM)
source("~/GitHub/MLCM/R/panelcv.R")
library(MLCM)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
timevar
!post_period %in% data[, timevar]
!post_period %in% data[, timevar]
if(!post_period %in% data[, timevar]){print("error")}
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
library(MLCM)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
library(CAST)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "block", nboot = 10)
prova <- sample(ids, size = length(ids), replace = T)
prova
sapply(prova, function(x)(intersect(which(data[, "ID"] %in% x), ind)), simplify = F)
which(data[, "ID"] %in% prova[1]
)
prova[1]
matrix(c(1,0.5,0.7,0.5, 1, 0.3, 0.7, 0.3, 1), nrow = 3, ncol = 3)
library(MLCM)
source("~/GitHub/MLCM/R/panelcv.R")
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
install.packages("rpart")
install.packages("rpart")
source("~/GitHub/MLCM/R/panelcv.R")
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
library(CAST)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
View(data.frame(ate = ate, data_panel[!ind, -c("Y", "ID", "Time")]))
View(data_panel[!ind, -c("Y", "ID", "Time")])
sum(!ind)
sum(ind)
View(data_panel[-ind, -c("Y", "ID", "Time")])
View(data_panel[-c(ind), -c("Y", "ID", "Time")])
View(data_panel[-ind, ])
View(data_panel[-ind, -c("Y","Time")])
View(data_panel[-ind, !names(data_panel %in% c("Y","Time","ID")])
View(data_panel[-ind, !names(data_panel %in% c("Y","Time","ID"))])
View(data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")])
View(data.frame(ate = ate, data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")]))
ate
View(data.frame(effect = obs-pred, data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")]))
View(data_panel)
View(data)
cate <- rpart(ate ~ ., method="anova", data = data.frame(effect = obs-pred, data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")]), cp = 0, minbucket = 0.05*length(obs))
library(rpart)
cate <- rpart(ate ~ ., method="anova", data = data.frame(effect = obs-pred, data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")]), cp = 0, minbucket = 0.05*length(obs))
length(obs-pred)
dim(data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")]))
dim(data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")])
cate <- rpart(effect ~ ., method="anova", data = data.frame(effect = obs-pred, data_panel[-ind, !names(data_panel) %in% c("Y","Time","ID")]), cp = 0, minbucket = 0.05*length(obs))
plot(cate)
text(cate, use.n = TRUE, cex = 0.8)
summary(cate)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
fit$cate
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, cate = TRUE)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE  = TRUE)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE  = TRUE)
plot(fit$cate)
summary(cate)
summary(fit$cate)
library(MLCM)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE  = TRUE)
plot(fit$cate)
text(fit$cate)
library(MLCM)
library(MLCM)
fit$cate$splits
fit$cate$where
class(fit$cate$where)
unique(fit$cate$where)
which(fit$cate$where == 2)
which(fit$cate$where == 5)
fit$cate$frame
pred <- predict(fit$cate, type = "vector")
View(data.frame(pred = pred, fit$where))
View(data.frame(pred = pred, fit$cate$where))
fit$cate
predict(fit$cate, type = "node")
predict(fit$cate, type = "class")
predict(fit$cate, type = "matrix")
predict(fit$cate, type = "vector")
pred[which(fit$cate$where == 14)]
mean(pred[which(fit$cate$where == 14)])
mean(pred[which(fit$cate$where == 5)])
mean(pred[which(fit$cate$where == 7)])
mean(pred[which(fit$cate$where == 6)])
pred[which(fit$cate$where == 6)]
which(fit$cate$where == 6)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
node.inf <- mapply(terminal.nodes, FUN = function(x){y <- effect[which(terminal == x)];
boot.dist <- matrix(sample(y, size = nboot*length(y), replace = TRUE),
nrow = nboot, ncol = length(y));
mean.cate <- colMeans(boot.dist);
var.cate <- var(mean.cate);
conf.cate <- quantile(mean.cate, probs = c(0.025, 0.975));
c(var.cate = var.cate, cate.lower = conf.cate[1], cate.upper = conf.cate[2])},
SIMPLIFY = TRUE)
node.inf <- mapply(terminal.nodes, FUN = function(x){y <- effect[which(terminal.nodes == x)];
boot.dist <- matrix(sample(y, size = nboot*length(y), replace = TRUE),
nrow = nboot, ncol = length(y));
mean.cate <- colMeans(boot.dist);
var.cate <- var(mean.cate);
conf.cate <- quantile(mean.cate, probs = c(0.025, 0.975));
c(var.cate = var.cate, cate.lower = conf.cate[1], cate.upper = conf.cate[2])},
SIMPLIFY = TRUE)
node.inf <- mapply(terminal.nodes, FUN = function(x){y <- effect[which(terminal.nodes == x)];
boot.dist <- matrix(sample(y, size = 1000*length(y), replace = TRUE),
nrow = nboot, ncol = length(y));
mean.cate <- colMeans(boot.dist);
var.cate <- var(mean.cate);
conf.cate <- quantile(mean.cate, probs = c(0.025, 0.975));
c(var.cate = var.cate, cate.lower = conf.cate[1], cate.upper = conf.cate[2])},
SIMPLIFY = TRUE)
node.inf <- mapply(terminal.nodes, FUN = function(x){y <- effect[which(terminal.nodes == x)];
boot.dist <- matrix(sample(y, size = 1000*length(y), replace = TRUE),
nrow = 1000, ncol = length(y));
mean.cate <- colMeans(boot.dist);
var.cate <- var(mean.cate);
conf.cate <- quantile(mean.cate, probs = c(0.025, 0.975));
c(var.cate = var.cate, cate.lower = conf.cate[1], cate.upper = conf.cate[2])},
SIMPLIFY = TRUE)
View(node.inf)
terminal.nodes
which(terminal.nodes == 5)
effect[which(terminal.nodes == 5)]
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
fit$cate.inf
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
node.inf <- mapply(x, FUN = function(x){y <- effect[which(terminal.nodes == x)];
boot.dist <- matrix(sample(y, size = nboot*length(y), replace = TRUE),
nrow = nboot, ncol = length(y));
mean.cate <- colMeans(boot.dist);
var.cate <- var(mean.cate);
conf.cate <- quantile(mean.cate, probs = c(0.025, 0.975));
c(cate = mean(y), var.cate = var.cate, cate.lower = conf.cate[1], cate.upper = conf.cate[2])},
SIMPLIFY = TRUE)
View(node.inf)
View(node.inf)
cate
summary(cate)
x
node.inf <- mapply(x, FUN = function(x){y <- effect[which(terminal.nodes == x)];
boot.dist <- matrix(sample(y, size = nboot*length(y), replace = TRUE),
nrow = nboot, ncol = length(y));
mean.cate <- colMeans(boot.dist);
var.cate <- var(mean.cate);
conf.cate <- quantile(mean.cate, probs = c(0.025, 0.975));
c(cate = mean(y), var.cate = var.cate, cate.lower = as.numeric(conf.cate[1]), cate.upper = conf.cate[2])},
SIMPLIFY = TRUE)
View(node.inf)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
fit$cate.inf
class(fit$cate)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
y <- effect[which(terminal.nodes == x)]
y <- effect[which(terminal.nodes == x[1])]
boot.dist <- matrix(sample(y, size = nboot*length(y), replace = TRUE),
nrow = nboot, ncol = length(y))
View(boot.dist)
var(rowMeans(boot.distrib))
var(rowMeans(boot.dist))
quantile(rowMeans(boot.dist), probs = c(0.025, 0.975))
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 1000, CATE = TRUE)
library(CAST)
library(bcaboot)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 1000, CATE = TRUE)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 1000, CATE = TRUE)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "bca", nboot = 1000, CATE = TRUE)
out2 <- bcajack2(B = Blist, alpha = alpha)
out2$lims
conf.ate <- out2$lims[c(1,3),"bca"]
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "bca", nboot = 100, CATE = TRUE)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "bca", nboot = 100, CATE = TRUE)
library8rpart
library(rpart)
library(MLCM)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "block", nboot = 100, CATE = TRUE)
fit$ate
data <- read.csv("data_ex.csv")
View(data)
rm(data)
load("~/GitHub/MLCM/data/data.rda")
View(data)
data <- data[,-1]
usethis::use_data(data)
usethis::use_data(data, overwrite = TRUE)
data <- read.csv("data_ex.csv")
data <- data[,-1]
View(data)
colnames(data) <- gsub(colnames(data), pattern = "dat.", replacement = "")
data <- data[,-16]
usethis::use_data(data, overwrite = TRUE)
library(MLCM)
View(data)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
library(CAST)
library(rpart)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
fit$ate
fit$best_method
View(data)
data <- data[data$ID <= 100, ]
dim(data)
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
data <- data[data$ID <= 50, ]
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10, CATE = TRUE)
warnings()
library(MLCM)
dim(data)
