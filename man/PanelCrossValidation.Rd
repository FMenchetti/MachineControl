% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/panelcv.R
\name{PanelCrossValidation}
\alias{PanelCrossValidation}
\title{Panel Cross Validation}
\usage{
PanelCrossValidation(
  data,
  int_date,
  pcv_block = 1,
  metric = "RMSE",
  default_par = list(gbm = list(depth = c(1, 2, 3), n.trees = c(500, 1000), shrinkage =
    seq(0.01, 0.1, by = 0.02), n.minobsinnode = c(10, 20)), rf = list(ntree = 500), pls =
    list(ncomp = c(1:5)), lasso = list(fraction = seq(0.1, 0.9, by = 0.1))),
  trControl = NULL,
  ML_methods = NULL
)
}
\arguments{
\item{data}{A 'PanelMLCM' object from a previous call to \code{as.PanelMLCM}.}

\item{int_date}{The date of the intervention, treatment, policy introduction or shock.}

\item{pcv_block}{Number of pre-intervention times to block for panel cross validation. Defaults to 1, see Details.}

\item{metric}{Character, the performance metric that should be used to select the optimal model.
Possible choices are either \code{"RMSE"} (the default) or \code{"Rsquared"}.}

\item{default_par}{List of parameters for the default ML algorithms. See Details.}

\item{trControl}{Optional, used to customize the training step. It must be the output from a call to \code{trainControl} from the \code{caret} package.}

\item{ML_methods}{Optional list of ML methods to be used as alternatives to the default methods. Each method must be supplied
as a named list of two elements: a character defining the method name from all the ones available in \code{caret}
and the grid of parameter values to tune via the panel cross validation. See Details and the examples for additional explanations.}
}
\value{
A list containing the following objects:
\itemize{
  \item \code{best}: the best-performing ML algorithm
  \item \code{best.metric}: the value of \code{metric} for the best-performing ML algorithm
  \item \code{all_methods}: detailed results for all the methods tried during the PCV routine
 }
}
\description{
This function implements the panel cross validation technique as described in
Cerqua A., Letta M. & Menchetti F., (2023) <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4315389>.
It works as a rolling window training and testing procedure where the ML methods are trained recursively on the
the observations in the first $t$ time periods and tested in the prediction of the next periods.
}
\details{
To speed up computational time in case of longer time series, users can increase the \code{pcv_block} parameter: \code{pcv_block = 1}
(the default) indicates to use the observations in the first time period as the first training sample and to test on the next period.
Then, the second training sample will be formed by the observations on the first two time periods and validation will be performed
on the third period and so on. For longer series, specifying \code{pcv_block > 1} reduces computational time. For example,
by setting \code{pcv_block = 4} when the length of the pre-intervention time series is 7 reduces the number of validation sets to 3 instead of 6.

By default, the panel cross validation routine compares two linear models (Partial Least Squares and LASSO) and two non-linear models
(Random Forests and Stochastic Gradient Boosting) in the prediction of the outcome in the testing sets. The default specification
is used internally by the \code{MLCM} function that records the best-performing ML algorithm and use it to estimate the ATE of the treatment.
Users can also change the default ML methods by the argument \code{ML_method}, a list of as many components as the ML methods that the users want
to try. Each element of \code{ML_method} should be a list of two elements: \code{method} must be a character with the method name from all the
ones available in \code{caret}; \code{tuneGrid} is a grid of parameter values to tune via the panel cross validation. See Example 2 for an
illustration.
}
\examples{

### Example 1. Changing the default training method

# Organizing the dataset
newdata <- as.PanelMLCM(y = data[, "Y"], timevar = data[, "year"], id = data[, "ID"],
                        x = data[, !(names(data) \%in\% c("Y", "ID", "year"))], y.lag = 1)

# Using the first two years for training and the last two years for testing
indices <- CAST::CreateSpacetimeFolds(newdata, timevar = "Time", k = length(unique(newdata$Time)))
trainx <- indices$indexOut[1:2]
testx <- indices$indexOut[3:4]
ctrl <- trainControl(index = trainx, indexOut = testx)

# Customized panel cross validation
pcv <- PanelCrossValidation(data = newdata, int_date = 2019, trControl = ctrl)

### Example 2. Changing ML methods and estimating ATE
set.seed(1)
enet <- list(method = "enet",
            tuneGrid = expand.grid(
              fraction = seq(0.1, 0.9, by = 0.1),
              lambda = seq(0.1, 0.9, by = 0.1)))

linreg <- list(method = "lm",
              tuneGrid = expand.grid(
                intercept = seq(0, 10, by = 0.5)))

pls <- list(method = "pls", tuneGrid = expand.grid(ncomp = c(1:5)))

pcv <- PanelCrossValidation(data = newdata, int_date = 2019, trControl = ctrl,
                            ML_methods = list(enet, linreg, pls))

causal <- MLCM(data = newdata, int_date = 2019, inf_type = "classic", PCV = pcv,
               nboot = 10, CATE = FALSE, y.lag = 2)

causal$estimate$ate
causal$estimate$conf.ate
}
