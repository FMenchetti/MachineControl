% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlcm.R
\name{MLCM}
\alias{MLCM}
\title{Machine Learning Control Method}
\usage{
MLCM(
  data,
  int_date,
  inf_type = "block",
  y = NULL,
  timevar = NULL,
  id = NULL,
  y.lag = 0,
  nboot = 1000,
  pcv_block = 1,
  metric = "RMSE",
  default_par = list(gbm = list(depth = c(1, 2, 3), n.trees = c(500, 1000), shrinkage =
    seq(0.01, 0.1, by = 0.02), n.minobsinnode = c(10, 20)), rf = list(ntree = 500), pls =
    list(ncomp = c(1:5)), lasso = list(fraction = seq(0.1, 0.9, by = 0.1))),
  PCV = NULL,
  CATE = FALSE,
  x.cate = NULL,
  alpha = 0.05,
  fe = FALSE
)
}
\arguments{
\item{data}{A panel dataset in long form, having one column for the time variable, one column for the units'
unique IDs, one column for the outcome variable and one or more columns for the covariates.}

\item{int_date}{The date of the intervention, treatment, policy introduction or shock. It must be contained in 'timevar'.
By default, this is the first period that the causal effect should be computed for.}

\item{inf_type}{Character, type of inference to be performed. Possible choices are 'classic', 'block', 'bc classic', 'bc block', 'bca'. Defaults to 'block'.}

\item{y}{Character, name of the column containing the outcome variable. It can be omitted for \code{PanelMLCM} objects.}

\item{timevar}{Character, name of the column containing the time variable. It can be omitted for \code{PanelMLCM} objects.}

\item{id}{Character, name of the column containing the ID's. It can be omitted for \code{PanelMLCM} objects.}

\item{y.lag}{Optional, number of lags of the dependent variable to include in the model. Defaults to zero.}

\item{nboot}{Number of bootstrap replications, defaults to 1000.}

\item{pcv_block}{Number of pre-intervention times to block for panel cross validation. Defaults to 1, see Details.}

\item{metric}{Character, the performance metric that should be used to select the optimal model.
Possible choices are either \code{"RMSE"} (the default) or \code{"Rsquared"}.}

\item{default_par}{List of parameters for the default ML algorithms. See the Details of \code{PanelCrossValidation}.}

\item{PCV}{Optional, list returned from a previous call to \code{PanelCrossValidation} or \code{PanelCrossValidationStag}.}

\item{CATE}{Whether the function should estimate also CATE (defaults to \code{FALSE}). Currently not allowed for staggered adoption. See Details.}

\item{x.cate}{Optional matrix or data.frame of external regressors to use as predictors of CATE. If missing, the
same covariates used to estimate ATE will be used. See Details.}

\item{alpha}{Confidence interval level to report for the ATE. Defaulting to 0.05 for a two sided
95\% confidence interval.}

\item{fe}{Logical, whether to include fixed effects dummy variables. Defaults to false.}
}
\value{
A list with the following components:
\itemize{
  \item \code{best_method}: the best-performing ML algorithm as selected by the PCV routine
  \item \code{int_date}: the intervention date
  \item \code{ate}: a list with the estimated ATE and its confidence interval
  \item \code{individual}: a list with the estimated individual effects and their confidence intervals
  \item \code{cate}: a list of class \code{rpart} with the estimated regression-tree-based CATE
  \item \code{cate.inf}: a matrix containing the variance of CATE and the confidence interval
  estimated by bootstrap
}
}
\description{
This function is the main workhorse of the package 'MachineControl'. It takes as
input a panel dataset, i.e., multiple units observed at several points in time and
exposed simultaneously to some policy (indicated by \code{int_date}). It then performs
the Panel Cross Validation (PCV) by comparing the predictive performance of several Machine
Learning (ML) methods in the pre-intervention periods and then outputs the estimated
Average Treatment Effect (ATE) of the policy and its confidence interval estimated by
bootstrap. Details on the causal assumptions, the estimation process and inference
can be found in Cerqua A., Letta M., and Menchetti F. (2023). The method is especially
suited when there are no control units available and it can also accomodate
staggered adoption settings where groups of units are treated or shocked at
different times. See Details.
}
\details{
The panel \code{data} must at least include the response variable, a column of the time variable,
and a column with the unit identifiers. Lagged values of the outcome, lagged or contemporaneous
exogenous covariates, control series can also be added in the panel dataset. The ML algorithms
will automatically treat every column that is left as additional information to improve the
prediction of the counterfactual post-intervention outcome. If \code{fe = TRUE}, N-1 dummy variables
will be added to the dataset, where N is the total number of units in the panel.

By default, the function internally uses \code{as.PanelMLCM} to organize a messy panel dataset and
then compares the performance of two linear models (Partial Least Squares and LASSO)
and two non-linear models (Random Forests and Stochastic Gradient Boosting) in one-step ahead
predictions by running internally the panel cross validation routine. The comparison is performed based on
the \code{metric} provided by the users and lasts until the end of the pre-intervention period.
Different ML algorithms can be selected by the user among all the options available in the \code{caret}
package. In this case, the users must start from a tidy panel dataset (from a previous call to \code{as.PanelMLCM})
and must execute their own panel cross validation. See the examples below.

By default, the function estimates the ATE by averaging the individual causal effects across units. This is done
for each time period after \code{int_date} (the first ATE will be computed exactly at \code{int_date}).

To speed up the PCV process, the user can 'block' some pre-intervention periods by increasing the
\code{pcv_block} parameter, e.g., \code{pcv_block = 1} (the default) indicates to use the observations
in the first time period as the first training sample and to test on the next period. Then, the second
training sample will be formed by the observations on the first two time periods. Validation will be
performed on the third period and so on. For longer series, specifying \code{pcv_block > 1} reduces computational time.
For example, by setting \code{pcv_block = 4} when the length of the pre-intervention time series is 7 reduces the number
of validation sets to 3 instead of 6.

By default, the function estimates an Average Treatment Effect (ATE), but when \code{CATE = TRUE} it also estimates
a Conditional Average Treatment Effect (CATE) as described in Cerqua A., Letta M. & Menchetti F.
<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4315389>. In short, CATE is estimated with a regression tree
and it is of interest when researchers suspect that the policy ('treatment' or 'intervention') has produced
heterogeneous effects on the units in the panel. For additional details on the causal estimands, estimation process and
underlying assumptions see the paper cited above.
}
\examples{

### Example 1. Estimating ATE (with default ML methods)

# Estimation
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", int_date = 2019,
            inf_type = "classic", nboot = 10, y.lag = 2)

# ATE
fit$ate$estimate
fit$ate$conf.interval

# Individual effects
head(fit$individual$estimate)
head(fit$individual$conf.interval)

### Example 2. Estimating ATE and CATE (with external regressors in CATE)

# Simulating time-varying external regressors
x.cate <- cbind(ID = rep(1:100, each = 2), year = rep(2019:2020, times = 100), x1 = rnorm(200),
                x2 = 2*rnorm(200), x3 = sample(1:5, size = 200, replace = TRUE))

# Estimation
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", int_date = 2019,
            inf_type = "classic", nboot = 10, CATE = TRUE, y.lag = 2, x.cate = x.cate)

# CATE
plot(fit, type = "cate")

}
