% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlcm.R
\name{MLCM}
\alias{MLCM}
\title{Machine Learning Control Method}
\usage{
MLCM(
  data,
  y = NULL,
  timevar = NULL,
  id = NULL,
  post_period,
  inf_type,
  nboot = 1000,
  pcv_block = 1,
  metric = "RMSE",
  PCV = NULL
)
}
\arguments{
\item{data}{A panel dataset in long form, having one column for the time variable, one column for the units'
unique IDs, one column for the outcome variable and one or more columns for the covariates.}

\item{y}{Character, name of the column containing the outcome variable. It can be omitted for \code{PanelMLCM} objects.}

\item{timevar}{Character, name of the column containing the time variable. It can be omitted for \code{PanelMLCM} objects.}

\item{id}{Character, name of the column containing the ID's. It can be omitted for \code{PanelMLCM} objects.}

\item{post_period}{The post-intervention period where the causal effect should be computed. It must be contained in 'timevar'.}

\item{inf_type}{Character, type of inference to be performed. Possible choices are 'classic', 'block', 'bc classic', 'bc block', 'bca'}

\item{nboot}{Number of bootstrap replications, defaults to 1000.}

\item{pcv_block}{Number of pre-intervention times to block for panel cross validation. Defaults to 1, see Details.}

\item{metric}{Character, the performance metric that should be used to select the optimal model.
Possible choices are either \code{"RMSE"} (the default) or \code{"Rsquared"}.}

\item{PCV}{Optional, best performing ML method as selected from a previous call to \code{PanelCrossValidation}.}
}
\value{
A list with the following components:
\itemize{
  \item \code{best_method}: the best-performing ML algorithm as selected by the PCV routine
  \item \code{fit}: the final result of the training step of the best-performing ML algorithm
  on all pre-intervention data
  \item \code{ate}: the estimated ATE
  \item \code{var.ate}: the variance of ATE as estimated by the bootstrap algorithm selected
  by the user in 'inf_type'
  \item \code{ate.lower}: lower bound of a 95% bootstrap confidence interval
  \item \code{ate.upper}: upper bound of a 95% bootstrap confidence interval
}
}
\description{
This function is the main workhorse of the package 'MachineControl'. It takes as
input a panel dataset, i.e., multiple units observed at several points in time and
exposed simultaneously to some policy (indicated by post_period). It then performs
the Panel Cross Validation (PCV) by comparing the predictive performance of several Machine
Learning (ML) methods in the pre-intervention periods and then outputs the estimated
Average Treatment Effect (ATE) of the policy and its confidence interval estimated by
bootstrap. Details on the causal assumptions, the estimation process and inference
can be found in Cerqua A., Letta M., and Menchetti F. (2023). The method is especially
suited when there are no control units available, but if there are control units these
can be easily added as control series among the covariates.
}
\details{
The panel \code{data} must at least include the response variable, a column of the time variable,
and a column with the unit identifiers. Lagged values of the outcome, lagged or contemporaneous
exogenous covariates, control series can also be added in the panel dataset. The ML algorithms
will automatically treat every column that is left as additional information to improve the
prediction of the counterfactual post-intervention outcome.

By default, the function internally uses \code{as.PanelMLCM} to organize a messy panel dataset and
then compares the performance of two linear models (Partial Least Squares and LASSO)
and two non-linear models (Random Forests and Stochastic Gradient Boosting) in one-step ahead
predictions by running internally the panel cross validation routine. The comparison is performed based on
the \code{metric} provided by the users and lasts until the end of the pre-intervention period.
Different ML algorithms can be selected by the user among all the options available in the \code{caret}
package. In this case, the users must start from a tidy panel dataset (from a previous call to \code{as.PanelMLCM})
and must execute their own panel cross validation. See the examples below.

The user can choose among many different bootstrap algorithms. For details see the documentation
of the function \code{boot_fun}. For details on the PCV see the documentation of the function
\code{PanelCrossValidation}.

To speed up the PCV process, the user can 'block' some pre-intervention periods by increasing the
\code{pcv_block} parameter, e.g., \code{pcv_block = 1} (the default) indicates to use the observations
in the first time period as the first training sample and to test on the next period. Then, the second
training sample will be formed by the observations on the first two time periods. Validation will be
performed on the third period and so on. For longer series, specifying \code{pcv_block > 1} reduces computational time.
For example, by setting \code{pcv_block = 4} when the length of the pre-intervention time series is 7 reduces the number
of validation sets to 3 instead of 6.
}
\examples{

### Example 1. Running MLCM with the default options

# Causal effect estimation of a policy occurred in 2020
fit <- MLCM(data = data, y = "Y", timevar = "year", id = "ID", post_period = 2020, inf_type = "classic", nboot = 10)
fit$ate

# Bootstrap confidence interval
c(fit$ate.lower, fit$ate.upper)

}
